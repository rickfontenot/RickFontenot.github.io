<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Rick Fontenot" />


<title>Case Study 2</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Rick Fontenot</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Budweiser.html">Case Study 1</a>
</li>
<li>
  <a href="CaseStudy2_ver4.html">Case Study 2</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Case Study 2</h1>
<h4 class="author">Rick Fontenot</h4>
<h4 class="date">2/26/2021</h4>

</div>


<p>Our Client DDSAnalytics specializes in talent management solutions for Fortune 100 companies to develop and retain employees. They have provided a dataset and asked us to identify factors that lead to attrition and to build a model to predict attrition. They are also interested in identifying some interesting trends between Job Roles as well as building a model to predict Salaries.</p>
<p>In addition to the analysis below, please check out our presentation in this <a href="https://youtu.be/vKZZ-pE8uhU">video</a> </p>
<p>To start the exploration we will load the data and perform univariate analysis</p>
<pre class="r"><code>DDS = read.csv(&quot;/Users/rickfontenot/Dropbox/SMU/GitHub/SMU/DS6306/CaseStudy2/CaseStudy2-data.csv&quot;, header = TRUE)

#Create List of numeric varibles
DDS_numeric &lt;- names(DDS %&gt;% select(where(is.numeric)))
#remove ID, EmployeeNumber and categorical/character variables
DDS_numeric &lt;- DDS_numeric[-c(1,7)]

#Create List of non-numeric varibles
DDS_categorical &lt;- names(DDS %&gt;% select(!where(is.numeric)))

#Convert character variables to factors
DDS[sapply(DDS, is.character)] &lt;- lapply(DDS[sapply(DDS, is.character)], as.factor)

plot_histogram(DDS)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/univariate-1.png" width="672" /><img src="CaseStudy2_ver4_files/figure-html/univariate-2.png" width="672" /></p>
<pre class="r"><code>#EmployeeNumber and ID are identifers, not for further analysis
#Non-normal or skewed distributions for DistanceFromHome, MonthlyIncome, NumCompaniesWorked, PercentSalaryHike, TotalWorkingYears, YearsInCurrentRole, YearsSinceLastPromotion

#Perform Log transformations for variables with non-normal distributions
DDS_transformed &lt;- DDS
DDS_transformed[&quot;logDistanceFromHome&quot;] = log(DDS_transformed$DistanceFromHome)
DDS_transformed[&quot;logMonthlyIncome&quot;] = log(DDS_transformed$MonthlyIncome)
DDS_transformed[&quot;logNumCompaniesWorked&quot;] = log(DDS_transformed$NumCompaniesWorked)
DDS_transformed[&quot;logPercentSalaryHike&quot;] = log(DDS_transformed$PercentSalaryHike)
DDS_transformed[&quot;logTotalWorkingYears&quot;] = log(DDS_transformed$TotalWorkingYears)
DDS_transformed[&quot;logYearsInCurrentRole&quot;] = log(DDS_transformed$YearsInCurrentRole)
DDS_transformed[&quot;logYearsSinceLastPromotion&quot;] = log(DDS_transformed$YearsSinceLastPromotion)

DDS_transformed = subset(DDS_transformed, select = -c(DistanceFromHome,MonthlyIncome,NumCompaniesWorked,PercentSalaryHike,TotalWorkingYears,YearsInCurrentRole,YearsSinceLastPromotion))

#Replace -inf from log transformation with 0
DDS_transformed &lt;- DDS_transformed %&gt;% mutate_if(is.numeric, function(x) ifelse(is.infinite(x), 0, x))

#Log transformations show more normal distributions
plot_histogram(DDS_transformed)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/univariate-3.png" width="672" /><img src="CaseStudy2_ver4_files/figure-html/univariate-4.png" width="672" /></p>
<pre class="r"><code>plot_bar(DDS)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/univariate-5.png" width="672" /><img src="CaseStudy2_ver4_files/figure-html/univariate-6.png" width="672" /></p>
<pre class="r"><code>#Over18 is all &quot;Y&quot;, StandardHours all 80, EmployeeCount all 1, may not be valuable for further analysis</code></pre>
<p>Explore Correlations and relationships between variables</p>
<pre class="r"><code>#Create function to summarize the most significant correlations since there are too many variables for one plot
corr_simple &lt;- function(data=df,sig=0.5){
  #convert data to numeric in order to run correlations
  #convert to factor first to keep the integrity of the data - each value will become a number rather than turn into NA
  df_cor &lt;- data %&gt;% mutate_if(is.character, as.factor)
  df_cor &lt;- df_cor %&gt;% mutate_if(is.factor, as.numeric)
  #run a correlation and drop the insignificant ones
  corr &lt;- cor(df_cor)
  #prepare to drop duplicates and correlations of 1     
  corr[lower.tri(corr,diag=TRUE)] &lt;- NA 
  #drop perfect correlations
  corr[corr == 1] &lt;- NA 
  #turn into a 3-column table
  corr &lt;- as.data.frame(as.table(corr))
  #remove the NA values from above 
  corr &lt;- na.omit(corr) 
  #select significant values  
  corr &lt;- subset(corr, abs(Freq) &gt; sig) 
  #sort by highest correlation
  corr &lt;- corr[order(-abs(corr$Freq)),] 
  #print table
  print(corr)
  #turn corr back into matrix in order to plot with corrplot
  mtx_corr &lt;- reshape2::acast(corr, Var1~Var2, value.var=&quot;Freq&quot;)
  
  #plot correlations visually
  corrplot(mtx_corr, is.corr=FALSE, tl.col=&quot;black&quot;, na.label=&quot; &quot;)
}
corr_simple(DDS_transformed)</code></pre>
<pre><code>## Warning in cor(df_cor): the standard deviation is zero</code></pre>
<pre><code>##                       Var1                       Var2       Freq
## 1095              JobLevel           logMonthlyIncome  0.9224617
## 1036        YearsAtCompany       YearsWithCurrManager  0.7652262
## 1252        YearsAtCompany      logYearsInCurrentRole  0.7402284
## 1219      logMonthlyIncome       logTotalWorkingYears  0.7230435
## 1174     PerformanceRating       logPercentSalaryHike  0.7229374
## 1253  YearsWithCurrManager      logYearsInCurrentRole  0.7117700
## 1203              JobLevel       logTotalWorkingYears  0.6758712
## 546             Department                    JobRole  0.6668582
## 882          MaritalStatus           StockOptionLevel -0.6450310
## 1288        YearsAtCompany logYearsSinceLastPromotion  0.6037156
## 1190                   Age       logTotalWorkingYears  0.6022018
## 1216        YearsAtCompany       logTotalWorkingYears  0.5909222
## 1258  logTotalWorkingYears      logYearsInCurrentRole  0.5282189
## 1289  YearsWithCurrManager logYearsSinceLastPromotion  0.5247190
## 1295 logYearsInCurrentRole logYearsSinceLastPromotion  0.5218594
## 987               JobLevel             YearsAtCompany  0.5205835
## 1217  YearsWithCurrManager       logTotalWorkingYears  0.5161444</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-EDA-1.png" width="672" /></p>
<pre class="r"><code>#High Correlations between:
#JobLevel   logMonthlyIncome    0.9224617   
#YearsAtCompany YearsWithCurrManager    0.7652262   
#YearsAtCompany logYearsInCurrentRole   0.7402284   
#logMonthlyIncome   logTotalWorkingYears    0.7230435   
#PerformanceRating  logPercentSalaryHike    0.7229374   
#YearsWithCurrManager   logYearsInCurrentRole   0.7117700   
#JobLevel   logTotalWorkingYears    0.6758712   
#Department JobRole 0.6668582   
#MaritalStatus  StockOptionLevel    -0.6450310    </code></pre>
<p>Evaluate significance of categorical variables effect on Attrition:</p>
<p>Based on Chi-Square tests, difference in Attrition rates are highly significant between categories for: OverTime, JobRole, MaritalStatus</p>
<p>There is also some significant difference for: Department, and BusinessTravel</p>
<pre class="r"><code>#Prepare tables and perform Chi-Square tests for categorical by Attrition
OverTime = table(DDS$Attrition, DDS$OverTime)
OverTimechisq &lt;- chisq.test(OverTime) #p-value = 2.333e-15
JobRole = table(DDS$Attrition, DDS$JobRole)
JobRolechisq &lt;- chisq.test(JobRole) #p-value = 3.647e-10</code></pre>
<pre><code>## Warning in chisq.test(JobRole): Chi-squared approximation may be incorrect</code></pre>
<pre class="r"><code>MaritalStatus = table(DDS$Attrition, DDS$MaritalStatus)
MaritalStatuschisq &lt;- chisq.test(MaritalStatus) #p-value = 3.379e-08
Department = table(DDS$Attrition, DDS$Department)
Departmentchisq &lt;- chisq.test(Department) #p-value = 0.009424
BusinessTravel = table(DDS$Attrition, DDS$BusinessTravel)
BusinessTravelchisq &lt;- chisq.test(BusinessTravel) #p-value = 0.04993
EducationField = table(DDS$Attrition, DDS$EducationField)
EducationFieldchisq &lt;- chisq.test(EducationField) #p-value = 0.2682</code></pre>
<pre><code>## Warning in chisq.test(EducationField): Chi-squared approximation may be
## incorrect</code></pre>
<pre class="r"><code>Gender = table(DDS$Attrition, DDS$Gender)
Genderchisq &lt;- chisq.test(Gender) #p-value = 0.5151

#Plots and observations for variables with significant difference in Attrition Rates

mosaicplot(OverTime, shade = TRUE, las=2, main = &quot;OverTime&quot;, pop = FALSE)</code></pre>
<pre><code>## Warning: In mosaicplot.default(OverTime, shade = TRUE, las = 2, main = &quot;OverTime&quot;, 
##     pop = FALSE) :
##  extra argument &#39;pop&#39; will be disregarded</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/Cat-v-Attrition-1.png" width="672" /></p>
<pre class="r"><code>OverTime</code></pre>
<pre><code>##      
##        No Yes
##   No  558 172
##   Yes  60  80</code></pre>
<pre class="r"><code>#Jobs with overtime have significantly higher attrition rate

mosaicplot(JobRole, shade = TRUE, las=2, main = &quot;JobRole&quot;, pop = FALSE)</code></pre>
<pre><code>## Warning: In mosaicplot.default(JobRole, shade = TRUE, las = 2, main = &quot;JobRole&quot;, 
##     pop = FALSE) :
##  extra argument &#39;pop&#39; will be disregarded</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/Cat-v-Attrition-2.png" width="672" /></p>
<pre class="r"><code>JobRole</code></pre>
<pre><code>##      
##       Healthcare Representative Human Resources Laboratory Technician Manager
##   No                         68              21                   123      47
##   Yes                         8               6                    30       4
##      
##       Manufacturing Director Research Director Research Scientist
##   No                      85                50                140
##   Yes                      2                 1                 32
##      
##       Sales Executive Sales Representative
##   No              167                   29
##   Yes              33                   24</code></pre>
<pre class="r"><code>#Sales representatives have significantly higher attrition rate
#Manufacturing Directors and Research Directors have significantly lower attrition rate
#May want to reduce level of factors from 9, to just 3 with SalesRep, Director, &amp; Other

DDS[&quot;JobRoleBin&quot;]=character()
DDS$JobRoleBin=&quot;Other&quot;

DDS$JobRole &lt;- as.character(DDS$JobRole)
DDS$JobRoleBin[DDS$JobRole %in% c(&quot;Research Director&quot;)] &lt;- &quot;Director&quot;
DDS$JobRoleBin[DDS$JobRole %in% c(&quot;Manufacturing Director&quot;)] &lt;- &quot;Director&quot;
DDS$JobRoleBin[DDS$JobRole %in% c(&quot;Sales Representative&quot;)] &lt;- &quot;SalesRep&quot;
DDS$JobRoleBin &lt;- factor(DDS$JobRoleBin)
DDS$JobRole &lt;- factor(DDS$JobRole)


JobRoleBin = table(DDS$Attrition, DDS$JobRoleBin)
JobRoleBinchisq &lt;- chisq.test(JobRoleBin) #p-value improves to 2.54e-12

mosaicplot(MaritalStatus, shade = TRUE, las=2, main = &quot;MaritalStatus&quot;, pop = FALSE)</code></pre>
<pre><code>## Warning: In mosaicplot.default(MaritalStatus, shade = TRUE, las = 2, main = &quot;MaritalStatus&quot;, 
##     pop = FALSE) :
##  extra argument &#39;pop&#39; will be disregarded</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/Cat-v-Attrition-3.png" width="672" /></p>
<pre class="r"><code>MaritalStatus</code></pre>
<pre><code>##      
##       Divorced Married Single
##   No       179     352    199
##   Yes       12      58     70</code></pre>
<pre class="r"><code>#Single workers have significantly high attrition rate
#Divorced workers have significantly low attirion rate

mosaicplot(Department, shade = TRUE, las=2, main = &quot;Department&quot;, pop = FALSE)</code></pre>
<pre><code>## Warning: In mosaicplot.default(Department, shade = TRUE, las = 2, main = &quot;Department&quot;, 
##     pop = FALSE) :
##  extra argument &#39;pop&#39; will be disregarded</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/Cat-v-Attrition-4.png" width="672" /></p>
<pre class="r"><code>Department</code></pre>
<pre><code>##      
##       Human Resources Research &amp; Development Sales
##   No               29                    487   214
##   Yes               6                     75    59</code></pre>
<pre class="r"><code>#Sales has significantly higher attrition rate, this variable may not have independence from JobRole variable

JobRole_v_Department = table(DDS$JobRole, DDS$Department)
JobRole_v_Department</code></pre>
<pre><code>##                            
##                             Human Resources Research &amp; Development Sales
##   Healthcare Representative               0                     76     0
##   Human Resources                        27                      0     0
##   Laboratory Technician                   0                    153     0
##   Manager                                 8                     23    20
##   Manufacturing Director                  0                     87     0
##   Research Director                       0                     51     0
##   Research Scientist                      0                    172     0
##   Sales Executive                         0                      0   200
##   Sales Representative                    0                      0    53</code></pre>
<pre class="r"><code>#Both Sales Reps and Sales Executives included in &quot;Sales&quot; Department, JobRole showed significant difference between Rep &amp; Exec. Based on Lack of Independence, Department could be dropped from Attrition rate predections</code></pre>
<p>Evaluate significance of Numerical Variables on Attrition</p>
<pre class="r"><code>#Create dataframe of numerical independent variables excluding Over18,StandardHours,EmployeeCount
#Use log transformed data to meet t-test assumptions
DDS_transformed[&quot;JobRoleBin&quot;]=character()
DDS_transformed$JobRoleBin=&quot;Other&quot;

DDS_transformed$JobRole &lt;- as.character(DDS$JobRole)
DDS_transformed$JobRoleBin[DDS_transformed$JobRole %in% c(&quot;Research Director&quot;)] &lt;- &quot;Director&quot;
DDS_transformed$JobRoleBin[DDS_transformed$JobRole %in% c(&quot;Manufacturing Director&quot;)] &lt;- &quot;Director&quot;
DDS_transformed$JobRoleBin[DDS_transformed$JobRole %in% c(&quot;Sales Representative&quot;)] &lt;- &quot;SalesRep&quot;
DDS_transformed$JobRoleBin &lt;- factor(DDS_transformed$JobRoleBin)
DDS_transformed$JobRole &lt;- factor(DDS_transformed$JobRole)


Numerical &lt;- DDS_transformed %&gt;% select(-DDS_categorical,-JobRoleBin,-Over18,-StandardHours,-EmployeeCount,Attrition)

Numerical_long &lt;- gather(Numerical, key=&quot;variable&quot;, value=&quot;value&quot;,-c(ID,Attrition))

stat.test &lt;- Numerical_long %&gt;%
  group_by(variable) %&gt;%
  t_test(value ~ Attrition) %&gt;%
  adjust_pvalue(method = &quot;BH&quot;) %&gt;%
  add_significance()

#Sort and display numerical variables with highest significant difference by Attrition
stat.test &lt;- stat.test %&gt;% select(p, everything())
stat.test &lt;- stat.test[order(stat.test$p),] 
stat.test</code></pre>
<pre><code>## # A tibble: 24 x 11
##          p variable .y.   group1 group2    n1    n2 statistic    df   p.adj
##      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
##  1 1.16e-8 logMont… value No     Yes      730   140      5.96  196. 2.14e-7
##  2 1.78e-8 logTota… value No     Yes      730   140      5.91  170. 2.14e-7
##  3 3.22e-7 logYear… value No     Yes      730   140      5.29  198. 2.42e-6
##  4 4.04e-7 JobLevel value No     Yes      730   140      5.23  212. 2.42e-6
##  5 2.00e-6 JobInvo… value No     Yes      730   140      4.92  176. 9.60e-6
##  6 5.08e-6 YearsWi… value No     Yes      730   140      4.68  210. 2.03e-5
##  7 3.86e-5 StockOp… value No     Yes      730   140      4.22  188. 1.32e-4
##  8 5.05e-5 Age      value No     Yes      730   140      4.15  185. 1.52e-4
##  9 2.56e-4 YearsAt… value No     Yes      730   140      3.73  192. 6.83e-4
## 10 1.50e-3 JobSati… value No     Yes      730   140      3.22  198. 3.60e-3
## # … with 14 more rows, and 1 more variable: p.adj.signif &lt;chr&gt;</code></pre>
<p>Variable Importance and selection for predicting Attrition</p>
<pre class="r"><code>DDS_transformed &lt;- DDS_transformed %&gt;% select(-EmployeeCount,-StandardHours,-Over18)
DDS_transformed &lt;- DDS_transformed %&gt;% select(Attrition, everything())

str(DDS_transformed)</code></pre>
<pre><code>## &#39;data.frame&#39;:    870 obs. of  34 variables:
##  $ Attrition                 : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ ID                        : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Age                       : int  32 40 35 32 24 27 41 37 34 34 ...
##  $ BusinessTravel            : Factor w/ 3 levels &quot;Non-Travel&quot;,&quot;Travel_Frequently&quot;,..: 3 3 2 3 2 2 3 3 3 2 ...
##  $ DailyRate                 : int  117 1308 200 801 567 294 1283 309 1333 653 ...
##  $ Department                : Factor w/ 3 levels &quot;Human Resources&quot;,..: 3 2 2 3 2 2 2 3 3 2 ...
##  $ Education                 : int  4 3 2 4 1 2 5 4 4 4 ...
##  $ EducationField            : Factor w/ 6 levels &quot;Human Resources&quot;,..: 2 4 2 3 6 2 4 2 2 6 ...
##  $ EmployeeNumber            : int  859 1128 1412 2016 1646 733 1448 1105 1055 1597 ...
##  $ EnvironmentSatisfaction   : int  2 3 3 3 1 4 2 4 3 4 ...
##  $ Gender                    : Factor w/ 2 levels &quot;Female&quot;,&quot;Male&quot;: 2 2 2 1 1 2 2 1 1 2 ...
##  $ HourlyRate                : int  73 44 60 48 32 32 90 88 87 92 ...
##  $ JobInvolvement            : int  3 2 3 3 3 3 4 2 3 2 ...
##  $ JobLevel                  : int  2 5 3 3 1 3 1 2 1 2 ...
##  $ JobRole                   : Factor w/ 9 levels &quot;Healthcare Representative&quot;,..: 8 6 5 8 7 5 7 8 9 1 ...
##  $ JobSatisfaction           : int  4 3 4 4 4 1 3 4 3 3 ...
##  $ MaritalStatus             : Factor w/ 3 levels &quot;Divorced&quot;,&quot;Married&quot;,..: 1 3 3 2 3 1 2 1 2 2 ...
##  $ MonthlyRate               : int  9250 17544 19944 24032 17218 4809 5561 24223 18410 15332 ...
##  $ OverTime                  : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 2 1 2 2 2 1 ...
##  $ PerformanceRating         : int  3 3 3 3 3 4 3 3 3 3 ...
##  $ RelationshipSatisfaction  : int  3 1 3 3 3 3 1 3 4 2 ...
##  $ StockOptionLevel          : int  1 0 0 2 0 2 0 3 1 1 ...
##  $ TrainingTimesLastYear     : int  3 2 2 3 2 4 5 5 2 3 ...
##  $ WorkLifeBalance           : int  2 4 3 3 3 2 2 3 3 2 ...
##  $ YearsAtCompany            : int  5 20 2 14 6 9 4 1 1 8 ...
##  $ YearsWithCurrManager      : int  3 9 2 7 3 7 3 0 0 7 ...
##  $ logDistanceFromHome       : num  2.565 2.639 2.89 0 0.693 ...
##  $ logMonthlyIncome          : num  8.39 9.88 9.14 9.25 8.23 ...
##  $ logNumCompaniesWorked     : num  0.693 0 0.693 0 0 ...
##  $ logPercentSalaryHike      : num  2.4 2.64 2.4 2.94 2.56 ...
##  $ logTotalWorkingYears      : num  2.08 3.04 2.3 2.64 1.79 ...
##  $ logYearsInCurrentRole     : num  0.693 1.946 0.693 2.303 1.099 ...
##  $ logYearsSinceLastPromotion: num  0 1.386 0.693 1.609 0 ...
##  $ JobRoleBin                : Factor w/ 3 levels &quot;Director&quot;,&quot;Other&quot;,..: 2 1 1 2 2 1 2 2 3 2 ...</code></pre>
<pre class="r"><code># prepare training scheme
control &lt;- trainControl(method=&quot;repeatedcv&quot;, number=10, repeats=3)
# train the model
model &lt;- train(Attrition~., data=DDS_transformed, method=&quot;lvq&quot;, trControl=control)
# estimate variable importance
importance &lt;- varImp(model, scale=FALSE)
# summarize importance
print(importance)</code></pre>
<pre><code>## ROC curve variable importance
## 
##   only 20 most important variables shown (out of 33)
## 
##                         Importance
## OverTime                    0.6679
## logMonthlyIncome            0.6567
## logTotalWorkingYears        0.6559
## YearsAtCompany              0.6470
## StockOptionLevel            0.6455
## MaritalStatus               0.6438
## JobLevel                    0.6406
## logYearsInCurrentRole       0.6362
## JobRoleBin                  0.6322
## YearsWithCurrManager        0.6291
## Age                         0.6265
## JobInvolvement              0.6159
## JobSatisfaction             0.5833
## JobRole                     0.5829
## Department                  0.5605
## logDistanceFromHome         0.5586
## EnvironmentSatisfaction     0.5532
## WorkLifeBalance             0.5491
## TrainingTimesLastYear       0.5428
## Education                   0.5384</code></pre>
<pre class="r"><code># plot importance
plot(importance)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/VarImportance-1.png" width="672" /></p>
<pre class="r"><code>library(CORElearn)
information.gain &lt;- attrEval(Attrition ~ ., data=DDS_transformed,  estimator = &quot;InfGain&quot;)
sort(information.gain)</code></pre>
<pre><code>##          PerformanceRating                     Gender 
##               0.0001666347               0.0004628770 
## logYearsSinceLastPromotion   RelationshipSatisfaction 
##               0.0017875032               0.0020659083 
##                  Education      TrainingTimesLastYear 
##               0.0020890277               0.0033208462 
##       logPercentSalaryHike                MonthlyRate 
##               0.0034209131               0.0035178832 
##                 HourlyRate                  DailyRate 
##               0.0044057689               0.0044863425 
##             BusinessTravel             EducationField 
##               0.0047673311               0.0049915400 
##             EmployeeNumber      logNumCompaniesWorked 
##               0.0068379340               0.0071332519 
##        logDistanceFromHome                 Department 
##               0.0074508166               0.0074648224 
##                         ID    EnvironmentSatisfaction 
##               0.0079917570               0.0083856564 
##            JobSatisfaction            WorkLifeBalance 
##               0.0085780754               0.0094374916 
##      logYearsInCurrentRole                        Age 
##               0.0203890981               0.0215535995 
##             JobInvolvement       YearsWithCurrManager 
##               0.0216600278               0.0255237214 
##       logTotalWorkingYears              MaritalStatus 
##               0.0282626078               0.0293144990 
##           logMonthlyIncome                   JobLevel 
##               0.0310985115               0.0317913272 
##             YearsAtCompany           StockOptionLevel 
##               0.0327292964               0.0394605817 
##                 JobRoleBin                   OverTime 
##               0.0451386017               0.0488108569 
##                    JobRole 
##               0.0515112956</code></pre>
<p>Build Naive Bayes predictor for Attrition starting with high importance variables, then tune based on correlated variables and p-values</p>
<pre class="r"><code>#Split Train &amp; Test
trainIndices = sample(seq(1:length(DDS_transformed$Age)),round(.7*length(DDS_transformed$Age)))
trainDDS = DDS_transformed[trainIndices,]
testDDS = DDS_transformed[-trainIndices,]

#Model 1 including all features with significant p-values or importance
features=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;logTotalWorkingYears&quot;,&quot;MaritalStatus&quot;,&quot;logYearsInCurrentRole&quot;,&quot;JobLevel&quot;,&quot;JobInvolvement&quot;,&quot;YearsWithCurrManager&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;YearsAtCompany&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity=70.59 % Acc=86.59 Sensitivity=88.99
model = naiveBayes(trainDDS[,features],as.factor(trainDDS$Attrition),laplace=1)
confusionMatrix(table(predict(model,testDDS[,features]),testDDS$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  188  16
##   Yes  31  26
##                                           
##                Accuracy : 0.8199          
##                  95% CI : (0.7678, 0.8646)
##     No Information Rate : 0.8391          
##     P-Value [Acc &gt; NIR] : 0.82369         
##                                           
##                   Kappa : 0.4173          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.04114         
##                                           
##             Sensitivity : 0.8584          
##             Specificity : 0.6190          
##          Pos Pred Value : 0.9216          
##          Neg Pred Value : 0.4561          
##              Prevalence : 0.8391          
##          Detection Rate : 0.7203          
##    Detection Prevalence : 0.7816          
##       Balanced Accuracy : 0.7387          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<pre class="r"><code>#Model 2: Remove Department since correlated with JobRoleBin
features2=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;logTotalWorkingYears&quot;,&quot;MaritalStatus&quot;,&quot;logYearsInCurrentRole&quot;,&quot;JobLevel&quot;,&quot;JobInvolvement&quot;,&quot;YearsWithCurrManager&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;YearsAtCompany&quot;,&quot;JobSatisfaction&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity=67.65 % Acc=85.82, Sensitivity=88.55 both are decreases from Model1
model = naiveBayes(trainDDS[,features2],as.factor(trainDDS$Attrition),laplace=1)
confusionMatrix(table(predict(model,testDDS[,features2]),testDDS$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  186  16
##   Yes  33  26
##                                           
##                Accuracy : 0.8123          
##                  95% CI : (0.7595, 0.8578)
##     No Information Rate : 0.8391          
##     P-Value [Acc &gt; NIR] : 0.89499         
##                                           
##                   Kappa : 0.4025          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.02227         
##                                           
##             Sensitivity : 0.8493          
##             Specificity : 0.6190          
##          Pos Pred Value : 0.9208          
##          Neg Pred Value : 0.4407          
##              Prevalence : 0.8391          
##          Detection Rate : 0.7126          
##    Detection Prevalence : 0.7739          
##       Balanced Accuracy : 0.7342          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<pre class="r"><code>#Model 3: Remove YearsAtCompany
features3=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;logTotalWorkingYears&quot;,&quot;MaritalStatus&quot;,&quot;logYearsInCurrentRole&quot;,&quot;JobLevel&quot;,&quot;JobInvolvement&quot;,&quot;YearsWithCurrManager&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity =67.65 % Acc=86.59  Sensitivity=89.43 Specificity decreased
model = naiveBayes(trainDDS[,features3],as.factor(trainDDS$Attrition),laplace=1)
confusionMatrix(table(predict(model,testDDS[,features3]),testDDS$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  190  17
##   Yes  29  25
##                                         
##                Accuracy : 0.8238        
##                  95% CI : (0.772, 0.868)
##     No Information Rate : 0.8391        
##     P-Value [Acc &gt; NIR] : 0.7782        
##                                         
##                   Kappa : 0.4149        
##                                         
##  Mcnemar&#39;s Test P-Value : 0.1048        
##                                         
##             Sensitivity : 0.8676        
##             Specificity : 0.5952        
##          Pos Pred Value : 0.9179        
##          Neg Pred Value : 0.4630        
##              Prevalence : 0.8391        
##          Detection Rate : 0.7280        
##    Detection Prevalence : 0.7931        
##       Balanced Accuracy : 0.7314        
##                                         
##        &#39;Positive&#39; Class : No            
## </code></pre>
<pre class="r"><code>#Model 4 Scale all numerical values
DDS_scaled &lt;- DDS_transformed %&gt;% mutate_if(is.numeric,scale)
trainIndices = sample(seq(1:length(DDS_transformed$Age)),round(.7*length(DDS_transformed$Age)))
trainDDS_scaled = DDS_scaled[trainIndices,]
testDDS_scaled = DDS_scaled[-trainIndices,]

features4=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;logTotalWorkingYears&quot;,&quot;MaritalStatus&quot;,&quot;logYearsInCurrentRole&quot;,&quot;JobLevel&quot;,&quot;JobInvolvement&quot;,&quot;YearsWithCurrManager&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;YearsAtCompany&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity =57.58 % Acc=86.21 Sensitivity=88.94 both are decreases from non-scaled model
model = naiveBayes(trainDDS_scaled[,features4],as.factor(trainDDS_scaled$Attrition),laplace=1)
confusionMatrix(table(predict(model,testDDS_scaled[,features4]),testDDS_scaled$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  182  26
##   Yes  30  23
##                                           
##                Accuracy : 0.7854          
##                  95% CI : (0.7306, 0.8337)
##     No Information Rate : 0.8123          
##     P-Value [Acc &gt; NIR] : 0.8816          
##                                           
##                   Kappa : 0.3179          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.6885          
##                                           
##             Sensitivity : 0.8585          
##             Specificity : 0.4694          
##          Pos Pred Value : 0.8750          
##          Neg Pred Value : 0.4340          
##              Prevalence : 0.8123          
##          Detection Rate : 0.6973          
##    Detection Prevalence : 0.7969          
##       Balanced Accuracy : 0.6639          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<pre class="r"><code>#Model 5 remove JobLevel since it is highly correlated with Monthly Income
features=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;logTotalWorkingYears&quot;,&quot;MaritalStatus&quot;,&quot;logYearsInCurrentRole&quot;,&quot;JobInvolvement&quot;,&quot;YearsWithCurrManager&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;YearsAtCompany&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity =67.65 % Acc=88.12 Sensitivity=91.19  lowered specificity but increased accuracy
model = naiveBayes(trainDDS[,features],as.factor(trainDDS$Attrition),laplace=1)
confusionMatrix(table(predict(model,testDDS[,features]),testDDS$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  192  17
##   Yes  27  25
##                                           
##                Accuracy : 0.8314          
##                  95% CI : (0.7804, 0.8748)
##     No Information Rate : 0.8391          
##     P-Value [Acc &gt; NIR] : 0.6688          
##                                           
##                   Kappa : 0.4305          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.1748          
##                                           
##             Sensitivity : 0.8767          
##             Specificity : 0.5952          
##          Pos Pred Value : 0.9187          
##          Neg Pred Value : 0.4808          
##              Prevalence : 0.8391          
##          Detection Rate : 0.7356          
##    Detection Prevalence : 0.8008          
##       Balanced Accuracy : 0.7360          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<pre class="r"><code>#Model 6: Remove YearsWithCurrManager &amp; YearsAtCompany since correlated with logYearsInCurrentRole which has lowest p-value
features6=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;logTotalWorkingYears&quot;,&quot;MaritalStatus&quot;,&quot;logYearsInCurrentRole&quot;,&quot;JobLevel&quot;,&quot;JobInvolvement&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity =67.65 % Acc=86.97 Sensitivity=89.87 lower specificity, slightly higher accuracy
model = naiveBayes(trainDDS[,features6],as.factor(trainDDS$Attrition),laplace=1)
confusionMatrix(table(predict(model,testDDS[,features6]),testDDS$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  192  17
##   Yes  27  25
##                                           
##                Accuracy : 0.8314          
##                  95% CI : (0.7804, 0.8748)
##     No Information Rate : 0.8391          
##     P-Value [Acc &gt; NIR] : 0.6688          
##                                           
##                   Kappa : 0.4305          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.1748          
##                                           
##             Sensitivity : 0.8767          
##             Specificity : 0.5952          
##          Pos Pred Value : 0.9187          
##          Neg Pred Value : 0.4808          
##              Prevalence : 0.8391          
##          Detection Rate : 0.7356          
##    Detection Prevalence : 0.8008          
##       Balanced Accuracy : 0.7360          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<pre class="r"><code>#Model 7: Remove YearsWithCurrManager &amp; logYearsInCurrentRole since correlated with YearsAtCompany which has highest variable importance
features7=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;logTotalWorkingYears&quot;,&quot;MaritalStatus&quot;,&quot;JobLevel&quot;,&quot;JobInvolvement&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;YearsAtCompany&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity =64.71 % Acc=87.74 Sensitivity=91.19 lower specificity but higher accuracy
model = naiveBayes(trainDDS[,features7],as.factor(trainDDS$Attrition),laplace=1)
confusionMatrix(table(predict(model,testDDS[,features7]),testDDS$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  193  18
##   Yes  26  24
##                                           
##                Accuracy : 0.8314          
##                  95% CI : (0.7804, 0.8748)
##     No Information Rate : 0.8391          
##     P-Value [Acc &gt; NIR] : 0.6688          
##                                           
##                   Kappa : 0.4204          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.2913          
##                                           
##             Sensitivity : 0.8813          
##             Specificity : 0.5714          
##          Pos Pred Value : 0.9147          
##          Neg Pred Value : 0.4800          
##              Prevalence : 0.8391          
##          Detection Rate : 0.7395          
##    Detection Prevalence : 0.8084          
##       Balanced Accuracy : 0.7264          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<pre class="r"><code>#Model 8 Remove logTotalWorkingYears since correlated with logMonthlyIncome
features8=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;MaritalStatus&quot;,&quot;logYearsInCurrentRole&quot;,&quot;JobLevel&quot;,&quot;JobInvolvement&quot;,&quot;YearsWithCurrManager&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;YearsAtCompany&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity =73.53 % Acc=87.36 Sensitivity=89.43 improved on both
model = naiveBayes(trainDDS[,features8],as.factor(trainDDS$Attrition),laplace=1)
confusionMatrix(table(predict(model,testDDS[,features8]),testDDS$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  194  15
##   Yes  25  27
##                                           
##                Accuracy : 0.8467          
##                  95% CI : (0.7972, 0.8882)
##     No Information Rate : 0.8391          
##     P-Value [Acc &gt; NIR] : 0.4072          
##                                           
##                   Kappa : 0.4823          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.1547          
##                                           
##             Sensitivity : 0.8858          
##             Specificity : 0.6429          
##          Pos Pred Value : 0.9282          
##          Neg Pred Value : 0.5192          
##              Prevalence : 0.8391          
##          Detection Rate : 0.7433          
##    Detection Prevalence : 0.8008          
##       Balanced Accuracy : 0.7644          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<pre class="r"><code>#Model 9 Combine improvements from Models 5,7 &amp; 8: Remove JobLevel, YearsWithCurrManager, logYearsInCurrentRole, logTotalWorkingYears
features9=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;MaritalStatus&quot;,&quot;JobInvolvement&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;YearsAtCompany&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity=58.82 % Acc=90.42 Sensitivity=95.15 sensitivity dropped below threshold
model = naiveBayes(trainDDS[,features9],as.factor(trainDDS$Attrition),laplace=1)
confusionMatrix(table(predict(model,testDDS[,features9]),testDDS$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  208  24
##   Yes  11  18
##                                           
##                Accuracy : 0.8659          
##                  95% CI : (0.8185, 0.9048)
##     No Information Rate : 0.8391          
##     P-Value [Acc &gt; NIR] : 0.13575         
##                                           
##                   Kappa : 0.4324          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.04252         
##                                           
##             Sensitivity : 0.9498          
##             Specificity : 0.4286          
##          Pos Pred Value : 0.8966          
##          Neg Pred Value : 0.6207          
##              Prevalence : 0.8391          
##          Detection Rate : 0.7969          
##    Detection Prevalence : 0.8889          
##       Balanced Accuracy : 0.6892          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<pre class="r"><code>#Model 10 Combine improvements from Models 5 &amp; 8: Remove JobLevel &amp; logTotalWorkingYears
features10=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;MaritalStatus&quot;,&quot;logYearsInCurrentRole&quot;,&quot;JobInvolvement&quot;,&quot;YearsWithCurrManager&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;YearsAtCompany&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity=73.53 % Acc=90.42 Sensitivity=92.95
model10 = naiveBayes(trainDDS[,features10],as.factor(trainDDS$Attrition),laplace=1)
confusionMatrix(table(predict(model10,testDDS[,features10]),testDDS$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  202  17
##   Yes  17  25
##                                           
##                Accuracy : 0.8697          
##                  95% CI : (0.8227, 0.9081)
##     No Information Rate : 0.8391          
##     P-Value [Acc &gt; NIR] : 0.1009          
##                                           
##                   Kappa : 0.5176          
##                                           
##  Mcnemar&#39;s Test P-Value : 1.0000          
##                                           
##             Sensitivity : 0.9224          
##             Specificity : 0.5952          
##          Pos Pred Value : 0.9224          
##          Neg Pred Value : 0.5952          
##              Prevalence : 0.8391          
##          Detection Rate : 0.7739          
##    Detection Prevalence : 0.8391          
##       Balanced Accuracy : 0.7588          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<pre class="r"><code>#Model 11 Combine improvements from Models 7 &amp; 8: Remove YearsWithCurrManager, logYearsInCurrentRole, logTotalWorkingYears
features11=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;MaritalStatus&quot;,&quot;JobLevel&quot;,&quot;JobInvolvement&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;YearsAtCompany&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity=64.71 % Acc=90.04 Sensitivity=93.83
model = naiveBayes(trainDDS[,features11],as.factor(trainDDS$Attrition),laplace=1)
confusionMatrix(table(predict(model,testDDS[,features11]),testDDS$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  200  21
##   Yes  19  21
##                                           
##                Accuracy : 0.8467          
##                  95% CI : (0.7972, 0.8882)
##     No Information Rate : 0.8391          
##     P-Value [Acc &gt; NIR] : 0.4072          
##                                           
##                   Kappa : 0.4214          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.8744          
##                                           
##             Sensitivity : 0.9132          
##             Specificity : 0.5000          
##          Pos Pred Value : 0.9050          
##          Neg Pred Value : 0.5250          
##              Prevalence : 0.8391          
##          Detection Rate : 0.7663          
##    Detection Prevalence : 0.8467          
##       Balanced Accuracy : 0.7066          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<pre class="r"><code>#Model 11 Combine improvements from Models 5 &amp; 7: Remove JobLevel, YearsWithCurrManager, logYearsInCurrentRole
features11=c(&quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;logTotalWorkingYears&quot;,&quot;MaritalStatus&quot;,&quot;JobInvolvement&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;YearsAtCompany&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;)

#Specificity=64.71 % Acc=88.89 Sensitivity=92.51
model = naiveBayes(trainDDS[,features11],as.factor(trainDDS$Attrition),laplace=1)
confusionMatrix(table(predict(model,testDDS[,features11]),testDDS$Attrition))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##      
##        No Yes
##   No  196  20
##   Yes  23  22
##                                           
##                Accuracy : 0.8352          
##                  95% CI : (0.7846, 0.8781)
##     No Information Rate : 0.8391          
##     P-Value [Acc &gt; NIR] : 0.6066          
##                                           
##                   Kappa : 0.407           
##                                           
##  Mcnemar&#39;s Test P-Value : 0.7604          
##                                           
##             Sensitivity : 0.8950          
##             Specificity : 0.5238          
##          Pos Pred Value : 0.9074          
##          Neg Pred Value : 0.4889          
##              Prevalence : 0.8391          
##          Detection Rate : 0.7510          
##    Detection Prevalence : 0.8276          
##       Balanced Accuracy : 0.7094          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<pre class="r"><code>#Best Model: Highest Accuracy while meeting Sensitivity&amp;Specificity&gt;60% is Model #10
#Features: &quot;OverTime&quot;,&quot;JobRoleBin&quot;,&quot;logMonthlyIncome&quot;,&quot;MaritalStatus&quot;,&quot;logYearsInCurrentRole&quot;,&quot;JobInvolvement&quot;,&quot;YearsWithCurrManager&quot;,&quot;StockOptionLevel&quot;,&quot;Age&quot;,&quot;YearsAtCompany&quot;,&quot;JobSatisfaction&quot;,&quot;Department&quot;,&quot;WorkLifeBalance&quot;,&quot;EnvironmentSatisfaction&quot;,&quot;BusinessTravel&quot;,&quot;logDistanceFromHome&quot;
#Accuracy=90.42% Specificity=73.53% Sensitivity=92.95</code></pre>
<p>Use Best Model to predict attrition for Competition Set</p>
<pre class="r"><code>Competition = read.csv(&quot;/Users/rickfontenot/Dropbox/SMU/GitHub/SMU/DS6306/CaseStudy2/CaseStudy2CompSet No Attrition.csv&quot;, header = TRUE)

#Select variables of interest
Competition &lt;- Competition %&gt;% select(ID,OverTime,JobRole,MonthlyIncome,MaritalStatus,YearsInCurrentRole,JobInvolvement,YearsWithCurrManager,StockOptionLevel,Age,YearsAtCompany,JobSatisfaction,Department,WorkLifeBalance,EnvironmentSatisfaction,BusinessTravel,DistanceFromHome)

#Transform logMonthlyIncome logYearsInCurrentRole logDistanceFromHome
Competition_transformed &lt;- Competition
Competition_transformed[&quot;logDistanceFromHome&quot;] = log(Competition_transformed$DistanceFromHome)
Competition_transformed[&quot;logMonthlyIncome&quot;] = log(Competition_transformed$MonthlyIncome)
Competition_transformed[&quot;logYearsInCurrentRole&quot;] = log(Competition_transformed$YearsInCurrentRole)

Competition_transformed = subset(Competition_transformed, select = -c(DistanceFromHome,MonthlyIncome,YearsInCurrentRole))

#Replace -inf from log transformation with 0
Competition_transformed &lt;- Competition_transformed %&gt;% mutate_if(is.numeric, function(x) ifelse(is.infinite(x), 0, x))

#Create Bins for Job Role
Competition_transformed$JobRole &lt;- as.character(Competition_transformed$JobRole)
Competition_transformed$JobRoleBin = &quot;Other&quot;
Competition_transformed$JobRoleBin[Competition_transformed$JobRole %in% c(&quot;Research Director&quot;)] &lt;- &quot;Director&quot;
Competition_transformed$JobRoleBin[Competition_transformed$JobRole %in% c(&quot;Manufacturing Director&quot;)] &lt;- &quot;Director&quot;
Competition_transformed$JobRoleBin[Competition_transformed$JobRole %in% c(&quot;Sales Representative&quot;)] &lt;- &quot;SalesRep&quot;
Competition_transformed$JobRoleBin &lt;- factor(Competition_transformed$JobRoleBin)
Competition_transformed$JobRole &lt;- factor(Competition_transformed$JobRole)
Competition_transformed = subset(Competition_transformed, select = -c(JobRole))

#Convert character variables to factors
Competition_transformed[sapply(Competition_transformed, is.character)] &lt;- lapply(Competition_transformed[sapply(Competition_transformed, is.character)], as.factor)

#Use Model#10 to make Attrition Predictions for competition set
Competition_transformed[&quot;Attrition&quot;]&lt;-predict(model10,Competition_transformed[,features10])
summary(Competition_transformed[&quot;Attrition&quot;])</code></pre>
<pre><code>##  Attrition
##  No :267  
##  Yes: 33</code></pre>
<pre class="r"><code>#Predictions: No=268 Yes=32, AttritionRate = 10.67%

#Reoder Columns to have ID and Attrition Prediction first
Competition_transformed &lt;- Competition_transformed %&gt;% select(ID,Attrition)


#Output File with predictions
write.csv(Competition_transformed,&quot;/Users/rickfontenot/Dropbox/SMU/GitHub/SMU/DS6306/CaseStudy2/Case2PredictionsFontenot Attrition.csv&quot;, row.names = TRUE)</code></pre>
<p>Correlations with Monthly Income</p>
<pre class="r"><code>DDS_cor &lt;- DDS %&gt;% select(-Over18,-EmployeeCount,-StandardHours,-ID,-EmployeeNumber)

#Convert Categoricals from int to factors
DDS_cor[,&#39;JobInvolvement&#39;]&lt;-factor(DDS_cor[,&#39;JobInvolvement&#39;])
DDS_cor[,&#39;JobLevel&#39;]&lt;-factor(DDS_cor[,&#39;JobLevel&#39;])
DDS_cor[,&#39;JobSatisfaction&#39;]&lt;-factor(DDS_cor[,&#39;JobSatisfaction&#39;])
DDS_cor[,&#39;JobInvolvement&#39;]&lt;-factor(DDS_cor[,&#39;JobInvolvement&#39;])
DDS_cor[,&#39;Education&#39;]&lt;-factor(DDS_cor[,&#39;Education&#39;])
DDS_cor[,&#39;EnvironmentSatisfaction&#39;]&lt;-factor(DDS_cor[,&#39;EnvironmentSatisfaction&#39;])
DDS_cor[,&#39;NumCompaniesWorked&#39;]&lt;-factor(DDS_cor[,&#39;NumCompaniesWorked&#39;])
DDS_cor[,&#39;PerformanceRating&#39;]&lt;-factor(DDS_cor[,&#39;PerformanceRating&#39;])
DDS_cor[,&#39;RelationshipSatisfaction&#39;]&lt;-factor(DDS_cor[,&#39;RelationshipSatisfaction&#39;])
DDS_cor[,&#39;StockOptionLevel&#39;]&lt;-factor(DDS_cor[,&#39;StockOptionLevel&#39;])
DDS_cor[,&#39;TrainingTimesLastYear&#39;]&lt;-factor(DDS_cor[,&#39;TrainingTimesLastYear&#39;])
DDS_cor[,&#39;WorkLifeBalance&#39;]&lt;-factor(DDS_cor[,&#39;WorkLifeBalance&#39;])
DDS_cor[,&#39;TrainingTimesLastYear&#39;]&lt;-factor(DDS_cor[,&#39;TrainingTimesLastYear&#39;])

#Split Train &amp; Test
trainIndices = sample(seq(1:length(DDS_cor$Age)),round(.7*length(DDS_cor$Age)))
trainDDS_cor = DDS_cor[trainIndices,]
testDDS_cor = DDS_cor[-trainIndices,]

#Build Model with all variables to create baseline, then use base model for selection methods
model &lt;- lm(MonthlyIncome ~ ., data = trainDDS_cor)
summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = MonthlyIncome ~ ., data = trainDDS_cor)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2914.0  -612.8   -59.4   570.4  4022.6 
## 
## Coefficients: (2 not defined because of singularities)
##                                    Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                       3.293e+03  8.576e+02   3.840 0.000138 ***
## Age                              -5.898e+00  6.942e+00  -0.850 0.395905    
## AttritionYes                     -1.063e+02  1.428e+02  -0.744 0.456932    
## BusinessTravelTravel_Frequently   2.011e+02  1.698e+02   1.184 0.236902    
## BusinessTravelTravel_Rarely       3.734e+02  1.442e+02   2.589 0.009876 ** 
## DailyRate                         2.611e-01  1.103e-01   2.367 0.018287 *  
## DepartmentResearch &amp; Development  2.240e+01  5.530e+02   0.041 0.967700    
## DepartmentSales                  -4.063e+02  5.524e+02  -0.735 0.462385    
## DistanceFromHome                 -5.645e+00  5.394e+00  -1.047 0.295780    
## Education2                       -3.233e+01  1.593e+02  -0.203 0.839256    
## Education3                       -3.236e+00  1.471e+02  -0.022 0.982456    
## Education4                        1.263e+02  1.605e+02   0.787 0.431708    
## Education5                       -3.744e+02  2.902e+02  -1.290 0.197597    
## EducationFieldLife Sciences       3.954e+02  4.346e+02   0.910 0.363295    
## EducationFieldMarketing           2.874e+02  4.621e+02   0.622 0.534315    
## EducationFieldMedical             3.181e+02  4.321e+02   0.736 0.461868    
## EducationFieldOther               2.834e+02  4.600e+02   0.616 0.538170    
## EducationFieldTechnical Degree    1.866e+02  4.472e+02   0.417 0.676700    
## EnvironmentSatisfaction2         -2.916e+02  1.383e+02  -2.109 0.035431 *  
## EnvironmentSatisfaction3         -9.825e+01  1.303e+02  -0.754 0.451094    
## EnvironmentSatisfaction4         -1.446e+02  1.275e+02  -1.134 0.257439    
## GenderMale                        1.137e+02  8.922e+01   1.275 0.202930    
## HourlyRate                       -8.983e-01  2.174e+00  -0.413 0.679579    
## JobInvolvement2                  -9.435e+01  1.999e+02  -0.472 0.637089    
## JobInvolvement3                  -1.454e+02  1.946e+02  -0.747 0.455144    
## JobInvolvement4                  -1.543e+02  2.378e+02  -0.649 0.516867    
## JobLevel2                         1.753e+03  1.821e+02   9.624  &lt; 2e-16 ***
## JobLevel3                         4.810e+03  2.433e+02  19.765  &lt; 2e-16 ***
## JobLevel4                         8.363e+03  3.849e+02  21.726  &lt; 2e-16 ***
## JobLevel5                         1.104e+04  4.714e+02  23.430  &lt; 2e-16 ***
## JobRoleHuman Resources           -6.694e+02  6.084e+02  -1.100 0.271716    
## JobRoleLaboratory Technician     -1.217e+03  2.257e+02  -5.392 1.05e-07 ***
## JobRoleManager                    3.717e+03  3.995e+02   9.303  &lt; 2e-16 ***
## JobRoleManufacturing Director     2.130e+02  2.096e+02   1.016 0.309875    
## JobRoleResearch Director          3.698e+03  2.802e+02  13.197  &lt; 2e-16 ***
## JobRoleResearch Scientist        -1.030e+03  2.317e+02  -4.445 1.07e-05 ***
## JobRoleSales Executive            4.212e+02  4.468e+02   0.943 0.346296    
## JobRoleSales Representative      -7.121e+02  4.975e+02  -1.431 0.152954    
## JobSatisfaction2                 -8.417e+01  1.415e+02  -0.595 0.552122    
## JobSatisfaction3                 -5.385e+01  1.274e+02  -0.423 0.672690    
## JobSatisfaction4                 -4.053e+00  1.256e+02  -0.032 0.974276    
## MaritalStatusMarried              2.228e+02  1.185e+02   1.881 0.060546 .  
## MaritalStatusSingle               2.221e+02  1.850e+02   1.201 0.230281    
## MonthlyRate                       4.313e-03  6.056e-03   0.712 0.476695    
## NumCompaniesWorked1              -1.472e+02  1.372e+02  -1.073 0.283552    
## NumCompaniesWorked2               2.223e+01  2.039e+02   0.109 0.913203    
## NumCompaniesWorked3               1.351e+02  2.026e+02   0.667 0.505010    
## NumCompaniesWorked4               5.405e+01  1.956e+02   0.276 0.782471    
## NumCompaniesWorked5               6.580e+01  2.592e+02   0.254 0.799695    
## NumCompaniesWorked6               7.039e+01  2.598e+02   0.271 0.786500    
## NumCompaniesWorked7              -1.082e+02  2.254e+02  -0.480 0.631213    
## NumCompaniesWorked8              -1.033e+02  2.984e+02  -0.346 0.729184    
## NumCompaniesWorked9               1.704e+02  2.882e+02   0.591 0.554748    
## OverTimeYes                       1.887e+02  1.019e+02   1.853 0.064468 .  
## PercentSalaryHike                -4.666e+00  1.902e+01  -0.245 0.806270    
## PerformanceRating4               -1.076e+02  1.928e+02  -0.558 0.577056    
## RelationshipSatisfaction2         1.825e+02  1.420e+02   1.285 0.199221    
## RelationshipSatisfaction3         1.237e+01  1.246e+02   0.099 0.920968    
## RelationshipSatisfaction4         8.636e+01  1.241e+02   0.696 0.486910    
## StockOptionLevel1                 5.395e+01  1.458e+02   0.370 0.711542    
## StockOptionLevel2                 1.843e+01  1.947e+02   0.095 0.924622    
## StockOptionLevel3                -1.232e+01  2.226e+02  -0.055 0.955882    
## TotalWorkingYears                 2.748e+01  1.538e+01   1.787 0.074530 .  
## TrainingTimesLastYear1           -3.094e+02  3.447e+02  -0.898 0.369781    
## TrainingTimesLastYear2           -3.097e+02  2.622e+02  -1.181 0.237984    
## TrainingTimesLastYear3           -2.593e+02  2.626e+02  -0.988 0.323836    
## TrainingTimesLastYear4           -2.934e+02  2.909e+02  -1.009 0.313529    
## TrainingTimesLastYear5           -2.280e+02  2.916e+02  -0.782 0.434631    
## TrainingTimesLastYear6            4.200e+00  3.285e+02   0.013 0.989803    
## WorkLifeBalance2                 -2.098e+01  2.045e+02  -0.103 0.918330    
## WorkLifeBalance3                 -5.075e+00  1.916e+02  -0.026 0.978875    
## WorkLifeBalance4                 -2.267e+02  2.212e+02  -1.025 0.305927    
## YearsAtCompany                   -3.229e+00  1.752e+01  -0.184 0.853830    
## YearsInCurrentRole                4.616e+01  2.060e+01   2.241 0.025430 *  
## YearsSinceLastPromotion          -5.207e+00  1.867e+01  -0.279 0.780430    
## YearsWithCurrManager             -2.248e+00  2.136e+01  -0.105 0.916249    
## JobRoleBinOther                          NA         NA      NA       NA    
## JobRoleBinSalesRep                       NA         NA      NA       NA    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1017 on 533 degrees of freedom
## Multiple R-squared:  0.9543, Adjusted R-squared:  0.9478 
## F-statistic: 148.3 on 75 and 533 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>#Variable Selection Methods

#Forward step selection 8 parameters included, RMSE = 955, Adj. R2=0.9572
step.forward &lt;- ols_step_forward_p(model)
step.forward</code></pre>
<pre><code>## 
##                                       Selection Summary                                        
## ----------------------------------------------------------------------------------------------
##         Variable                                 Adj.                                             
## Step            Entered            R-Square    R-Square      C(p)         AIC          RMSE       
## ----------------------------------------------------------------------------------------------
##    1    JobLevel                     0.9186      0.9181    343.6225    10444.6863    1274.8800    
##    2    JobRole                      0.9474      0.9463     10.3098    10195.0766    1031.9482    
##    3    TotalWorkingYears            0.9490      0.9479     -6.2378    10178.3751    1017.0781    
##    4    BusinessTravel               0.9500      0.9488    -16.7861    10169.3889    1007.9872    
##    5    YearsInCurrentRole           0.9504      0.9490    -18.4920    10167.5002    1005.6224    
##    6    DailyRate                    0.9507      0.9493    -20.1553    10165.6315    1003.2810    
##    7    OverTime                     0.9509      0.9494    -20.7162    10164.9124    1001.8918    
##    8    EnvironmentSatisfaction      0.9513      0.9496    -23.7096    10165.5753    1000.0570    
##    9    Gender                       0.9515      0.9497    -23.4910    10165.6599     999.3371    
##   10    MaritalStatus                0.9518      0.9498    -24.6383    10166.2611     998.2574    
##   11    PerformanceRating            0.9519      0.9498    -24.1650    10166.6055     997.7560    
##   12    DistanceFromHome             0.9520      0.9499    -23.5838    10167.0629     997.3489    
##   13    YearsAtCompany               0.9521      0.9499    -22.8247    10167.7105     997.0991    
## ----------------------------------------------------------------------------------------------</code></pre>
<pre class="r"><code>#Backward step selection 18 parameters removed (30-18=12 remain), RMSE = 952, Adj. R2=0.9575
step.backward &lt;- ols_step_backward_p(model)
step.backward</code></pre>
<pre><code>## 
## 
##                                       Elimination Summary                                       
## -----------------------------------------------------------------------------------------------
##         Variable                                  Adj.                                             
## Step            Removed             R-Square    R-Square      C(p)         AIC          RMSE       
## -----------------------------------------------------------------------------------------------
##    1    StockOptionLevel              0.9542      0.9481    -15.7610    10233.8772    1014.6579    
##    2    YearsWithCurrManager          0.9542      0.9482    -17.7514    10231.8882    1013.7219    
##    3    JobSatisfaction               0.9542      0.9484    -19.1970    10226.5210    1011.4274    
##    4    NumCompaniesWorked            0.9538      0.9489    -16.7445    10213.5797    1007.2776    
##    5    JobInvolvement                0.9538      0.9491    -18.0952    10208.3138    1005.1424    
##    6    EducationField                0.9535      0.9493    -17.5656    10201.1657    1002.9664    
##    7    PercentSalaryHike             0.9535      0.9494    -19.5386    10199.1962    1002.0924    
##    8    YearsSinceLastPromotion       0.9535      0.9495    -21.4616    10197.2827    1001.2668    
##    9    TrainingTimesLastYear         0.9533      0.9497    -20.1207    10189.0283     999.0035    
##   10    HourlyRate                    0.9532      0.9498    -21.9377    10187.2328     998.2882    
##   11    Department                    0.9531      0.9498    -22.7954    10184.5078     997.5728    
##   12    MonthlyRate                   0.9531      0.9499    -24.2706    10183.0926     997.1745    
##   13    Age                           0.9531      0.9499    -25.7898    10181.6279     996.7374    
##   14    RelationshipSatisfaction      0.9528      0.9499    -24.9721    10178.7558     996.6809    
##   15    WorkLifeBalance               0.9525      0.9499    -23.8018    10176.2558     996.9427    
##   16    Attrition                     0.9525      0.9499    -25.0076    10175.1296     996.7932    
##   17    Education                     0.9521      0.9499    -22.8247    10171.7105     997.0991    
## -----------------------------------------------------------------------------------------------</code></pre>
<pre class="r"><code>#Stepwise selection 6 parameters, RMSE=957, Adj. R2=0.957
stepwise &lt;- ols_step_both_p(model)
stepwise</code></pre>
<pre><code>## 
##                                      Stepwise Selection Summary                                       
## -----------------------------------------------------------------------------------------------------
##                                Added/                   Adj.                                             
## Step         Variable         Removed     R-Square    R-Square      C(p)         AIC          RMSE       
## -----------------------------------------------------------------------------------------------------
##    1         JobLevel         addition       0.919       0.918    343.6220    10444.6863    1274.8800    
##    2         JobRole          addition       0.947       0.946     10.3100    10195.0766    1031.9482    
##    3    TotalWorkingYears     addition       0.949       0.948     -6.2380    10178.3751    1017.0781    
##    4      BusinessTravel      addition       0.950       0.949    -16.7860    10169.3889    1007.9872    
##    5    YearsInCurrentRole    addition       0.950       0.949    -18.4920    10167.5002    1005.6224    
##    6        DailyRate         addition       0.951       0.949    -20.1550    10165.6315    1003.2810    
## -----------------------------------------------------------------------------------------------------</code></pre>
<pre class="r"><code>#Best fit from forward selection includes parameters: JobLevel + JobRole + TotalWorkingYears + BusinessTravel + Education + DailyRate + JobInvolvement + YearsWithCurrManager

#Examine scatter plots to look for any non-linear relationships that may need transformation
plot(DDS_cor$JobLevel,DDS_cor$MonthlyIncome)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-1.png" width="672" /></p>
<pre class="r"><code>plot(DDS_cor$JobRole,DDS_cor$MonthlyIncome)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-2.png" width="672" /></p>
<pre class="r"><code>plot(DDS_cor$TotalWorkingYears,DDS_cor$MonthlyIncome)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-3.png" width="672" /></p>
<pre class="r"><code>plot(DDS_cor$BusinessTravel,DDS_cor$MonthlyIncome)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-4.png" width="672" /></p>
<pre class="r"><code>plot(DDS_cor$Education,DDS_cor$MonthlyIncome)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-5.png" width="672" /></p>
<pre class="r"><code>plot(DDS_cor$DailyRate,DDS_cor$MonthlyIncome)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-6.png" width="672" /></p>
<pre class="r"><code>plot(DDS_cor$JobInvolvement,DDS_cor$MonthlyIncome)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-7.png" width="672" /></p>
<pre class="r"><code>plot(DDS_cor$YearsWithCurrManager,DDS_cor$MonthlyIncome)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-8.png" width="672" /></p>
<pre class="r"><code>#Model2 based on variables from forward and backward selection methods
model2 &lt;- lm(MonthlyIncome ~ JobLevel + JobRole + TotalWorkingYears + BusinessTravel + Education + DailyRate + JobInvolvement + YearsWithCurrManager, data = trainDDS_cor)
summary(model2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = MonthlyIncome ~ JobLevel + JobRole + TotalWorkingYears + 
##     BusinessTravel + Education + DailyRate + JobInvolvement + 
##     YearsWithCurrManager, data = trainDDS_cor)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2944.7  -633.6   -48.2   587.1  4121.0 
## 
## Coefficients:
##                                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                      3122.2823   320.9111   9.729  &lt; 2e-16 ***
## JobLevel2                        1767.7393   170.6807  10.357  &lt; 2e-16 ***
## JobLevel3                        4859.3162   231.0134  21.035  &lt; 2e-16 ***
## JobLevel4                        8282.5682   356.2634  23.248  &lt; 2e-16 ***
## JobLevel5                       10909.3737   431.1512  25.303  &lt; 2e-16 ***
## JobRoleHuman Resources           -948.6995   303.5583  -3.125  0.00186 ** 
## JobRoleLaboratory Technician    -1189.6939   213.2866  -5.578 3.73e-08 ***
## JobRoleManager                   3543.6464   304.7739  11.627  &lt; 2e-16 ***
## JobRoleManufacturing Director     179.6723   197.0673   0.912  0.36229    
## JobRoleResearch Director         3727.9761   260.2649  14.324  &lt; 2e-16 ***
## JobRoleResearch Scientist        -990.2517   218.8335  -4.525 7.32e-06 ***
## JobRoleSales Executive            -12.4444   164.3653  -0.076  0.93967    
## JobRoleSales Representative     -1168.3951   262.4640  -4.452 1.02e-05 ***
## TotalWorkingYears                  37.3356    10.6327   3.511  0.00048 ***
## BusinessTravelTravel_Frequently   227.5666   161.2149   1.412  0.15861    
## BusinessTravelTravel_Rarely       435.1940   136.3821   3.191  0.00149 ** 
## Education2                        -20.0077   148.8033  -0.134  0.89309    
## Education3                          1.4892   137.8888   0.011  0.99139    
## Education4                        129.4419   145.7162   0.888  0.37474    
## Education5                       -383.2663   266.1135  -1.440  0.15034    
## DailyRate                           0.2196     0.1054   2.082  0.03773 *  
## JobInvolvement2                   -55.4742   190.3277  -0.291  0.77080    
## JobInvolvement3                  -123.3775   181.7777  -0.679  0.49758    
## JobInvolvement4                  -122.7514   223.6491  -0.549  0.58331    
## YearsWithCurrManager                7.8955    13.9961   0.564  0.57289    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1007 on 584 degrees of freedom
## Multiple R-squared:  0.9509, Adjusted R-squared:  0.9489 
## F-statistic: 471.1 on 24 and 584 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>mse=mean(residuals(model2)^2)
mse</code></pre>
<pre><code>## [1] 972800.5</code></pre>
<pre class="r"><code>rmse=sqrt(mse)
rmse #935</code></pre>
<pre><code>## [1] 986.3065</code></pre>
<pre class="r"><code>plot(model2, which=1, col=c(&quot;blue&quot;)) # Residuals vs Fitted Plot</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-9.png" width="672" /></p>
<pre class="r"><code>plot(model2, which=2, col=c(&quot;red&quot;))  # Q-Q Plot</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-10.png" width="672" /></p>
<pre class="r"><code>plot(model2, which=3, col=c(&quot;blue&quot;))  # Scale-Location Plot</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-11.png" width="672" /></p>
<pre class="r"><code>plot(model2, which=4, col=c(&quot;blue&quot;))  # CooksD</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-12.png" width="672" /></p>
<pre class="r"><code>plot(model2, which=5, col=c(&quot;blue&quot;))  # Residuals vs Leverage</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-13.png" width="672" /></p>
<pre class="r"><code>#Model3 remove YearsWithCurrentManager which had high p-value in Model2
model3 &lt;- lm(MonthlyIncome ~ JobLevel + JobRole + TotalWorkingYears + BusinessTravel + Education + DailyRate + JobInvolvement, data = trainDDS_cor)
summary(model3)</code></pre>
<pre><code>## 
## Call:
## lm(formula = MonthlyIncome ~ JobLevel + JobRole + TotalWorkingYears + 
##     BusinessTravel + Education + DailyRate + JobInvolvement, 
##     data = trainDDS_cor)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2933.5  -658.4   -52.0   551.6  4115.4 
## 
## Coefficients:
##                                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                      3129.7785   320.4490   9.767  &lt; 2e-16 ***
## JobLevel2                        1772.6763   170.3568  10.406  &lt; 2e-16 ***
## JobLevel3                        4868.9522   230.2468  21.147  &lt; 2e-16 ***
## JobLevel4                        8268.0628   355.1271  23.282  &lt; 2e-16 ***
## JobLevel5                       10897.2956   430.3683  25.321  &lt; 2e-16 ***
## JobRoleHuman Resources           -942.7707   303.1995  -3.109  0.00197 ** 
## JobRoleLaboratory Technician    -1184.3781   212.9541  -5.562 4.07e-08 ***
## JobRoleManager                   3537.1067   304.3759  11.621  &lt; 2e-16 ***
## JobRoleManufacturing Director     183.6127   196.8286   0.933  0.35128    
## JobRoleResearch Director         3720.2851   259.7561  14.322  &lt; 2e-16 ***
## JobRoleResearch Scientist        -985.5274   218.5457  -4.509 7.85e-06 ***
## JobRoleSales Executive             -7.2524   164.0118  -0.044  0.96475    
## JobRoleSales Representative     -1167.5192   262.3065  -4.451 1.02e-05 ***
## TotalWorkingYears                  39.7855     9.6997   4.102 4.68e-05 ***
## BusinessTravelTravel_Frequently   228.8190   161.1056   1.420  0.15605    
## BusinessTravelTravel_Rarely       432.7286   136.2326   3.176  0.00157 ** 
## Education2                        -24.0160   148.5469  -0.162  0.87162    
## Education3                         -1.0371   137.7357  -0.008  0.99399    
## Education4                        127.6729   145.5975   0.877  0.38091    
## Education5                       -377.6771   265.7740  -1.421  0.15584    
## DailyRate                           0.2186     0.1054   2.075  0.03845 *  
## JobInvolvement2                   -56.1418   190.2131  -0.295  0.76798    
## JobInvolvement3                  -126.4450   181.5905  -0.696  0.48651    
## JobInvolvement4                  -118.4917   223.3913  -0.530  0.59602    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1007 on 585 degrees of freedom
## Multiple R-squared:  0.9509, Adjusted R-squared:  0.9489 
## F-statistic: 492.1 on 23 and 585 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>mse=mean(residuals(model3)^2)
mse</code></pre>
<pre><code>## [1] 973330.6</code></pre>
<pre class="r"><code>rmse=sqrt(mse)
rmse #936</code></pre>
<pre><code>## [1] 986.5752</code></pre>
<pre class="r"><code>plot(model3, which=1, col=c(&quot;blue&quot;)) # Residuals vs Fitted Plot</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-14.png" width="672" /></p>
<pre class="r"><code>plot(model3, which=2, col=c(&quot;red&quot;))  # Q-Q Plot</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-15.png" width="672" /></p>
<pre class="r"><code>plot(model3, which=3, col=c(&quot;blue&quot;))  # Scale-Location Plot</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-16.png" width="672" /></p>
<pre class="r"><code>plot(model3, which=4, col=c(&quot;blue&quot;))  # CooksD</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-17.png" width="672" /></p>
<pre class="r"><code>plot(model3, which=5, col=c(&quot;blue&quot;))  # Residuals vs Leverage</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-18.png" width="672" /></p>
<pre class="r"><code>#Model4 remove DailyRate which had high p-value in Model3
model4 &lt;- lm(MonthlyIncome ~ JobLevel + JobRole + TotalWorkingYears + BusinessTravel + Education + JobInvolvement, data = trainDDS_cor)
summary(model4)</code></pre>
<pre><code>## 
## Call:
## lm(formula = MonthlyIncome ~ JobLevel + JobRole + TotalWorkingYears + 
##     BusinessTravel + Education + JobInvolvement, data = trainDDS_cor)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2861.7  -618.2   -82.9   585.7  4251.7 
## 
## Coefficients:
##                                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                      3286.123    312.339  10.521  &lt; 2e-16 ***
## JobLevel2                        1775.610    170.831  10.394  &lt; 2e-16 ***
## JobLevel3                        4863.215    230.878  21.064  &lt; 2e-16 ***
## JobLevel4                        8262.369    356.116  23.201  &lt; 2e-16 ***
## JobLevel5                       10940.535    431.074  25.380  &lt; 2e-16 ***
## JobRoleHuman Resources           -950.592    304.030  -3.127  0.00186 ** 
## JobRoleLaboratory Technician    -1193.129    213.512  -5.588 3.52e-08 ***
## JobRoleManager                   3497.418    304.629  11.481  &lt; 2e-16 ***
## JobRoleManufacturing Director     187.935    197.372   0.952  0.34140    
## JobRoleResearch Director         3696.351    260.230  14.204  &lt; 2e-16 ***
## JobRoleResearch Scientist        -994.350    219.120  -4.538 6.90e-06 ***
## JobRoleSales Executive            -14.821    164.433  -0.090  0.92821    
## JobRoleSales Representative     -1171.070    263.039  -4.452 1.02e-05 ***
## TotalWorkingYears                  39.724      9.727   4.084 5.04e-05 ***
## BusinessTravelTravel_Frequently   220.528    161.509   1.365  0.17265    
## BusinessTravelTravel_Rarely       436.963    136.601   3.199  0.00145 ** 
## Education2                        -35.060    148.869  -0.236  0.81389    
## Education3                         -9.151    138.068  -0.066  0.94718    
## Education4                        116.177    145.902   0.796  0.42620    
## Education5                       -373.827    266.516  -1.403  0.16125    
## JobInvolvement2                   -29.049    190.299  -0.153  0.87873    
## JobInvolvement3                   -84.851    180.989  -0.469  0.63937    
## JobInvolvement4                   -88.940    223.564  -0.398  0.69090    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1009 on 586 degrees of freedom
## Multiple R-squared:  0.9505, Adjusted R-squared:  0.9486 
## F-statistic: 511.4 on 22 and 586 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>mse=mean(residuals(model3)^2)
mse</code></pre>
<pre><code>## [1] 973330.6</code></pre>
<pre class="r"><code>rmse=sqrt(mse)
rmse #936</code></pre>
<pre><code>## [1] 986.5752</code></pre>
<pre class="r"><code>plot(model4, which=1, col=c(&quot;blue&quot;)) # Residuals vs Fitted Plot</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-19.png" width="672" /></p>
<pre class="r"><code>plot(model4, which=2, col=c(&quot;red&quot;))  # Q-Q Plot</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-20.png" width="672" /></p>
<pre class="r"><code>plot(model4, which=3, col=c(&quot;blue&quot;))  # Scale-Location Plot</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-21.png" width="672" /></p>
<pre class="r"><code>plot(model4, which=4, col=c(&quot;blue&quot;))  # CooksD</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-22.png" width="672" /></p>
<pre class="r"><code>plot(model4, which=5, col=c(&quot;blue&quot;))  # Residuals vs Leverage</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-23.png" width="672" /></p>
<pre class="r"><code>plot(trainDDS_cor$JobLevel,residuals(model4))</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-24.png" width="672" /></p>
<pre class="r"><code>plot(trainDDS_cor$JobRole,residuals(model4))</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-25.png" width="672" /></p>
<pre class="r"><code>plot(trainDDS_cor$TotalWorkingYears,residuals(model4))</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-26.png" width="672" /></p>
<pre class="r"><code>plot(trainDDS_cor$BusinessTravel,residuals(model4))</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-27.png" width="672" /></p>
<pre class="r"><code>plot(trainDDS_cor$Education,residuals(model4))</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-28.png" width="672" /></p>
<pre class="r"><code>plot(trainDDS_cor$JobInvolvement,residuals(model4))</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/corr-Income-29.png" width="672" /></p>
<pre class="r"><code>#Model4 Predictions on Testing set
testDDS_cor$prediction &lt;- predict(model4, testDDS_cor)
testDDS_cor$residual &lt;- testDDS_cor$MonthlyIncome - testDDS_cor$prediction
mse=mean((testDDS_cor$residual)^2)
mse</code></pre>
<pre><code>## [1] 1002000</code></pre>
<pre class="r"><code>rmse=sqrt(mse)
rmse #1115</code></pre>
<pre><code>## [1] 1000.999</code></pre>
<p>Use Best Model to predict attrition for Competition Set</p>
<pre class="r"><code>Competition2 = read.csv(&quot;/Users/rickfontenot/Dropbox/SMU/GitHub/SMU/DS6306/CaseStudy2/CaseStudy2CompSet No Salary.csv&quot;, header = TRUE)

#Select variables of interest
Competition2 &lt;- Competition2 %&gt;% select(ID,JobLevel,JobRole,TotalWorkingYears,BusinessTravel,Education,JobInvolvement)


#Convert Categoricals from int to factors
Competition2[,&#39;JobInvolvement&#39;]&lt;-factor(Competition2[,&#39;JobInvolvement&#39;])
Competition2[,&#39;JobLevel&#39;]&lt;-factor(Competition2[,&#39;JobLevel&#39;])
Competition2[,&#39;JobInvolvement&#39;]&lt;-factor(Competition2[,&#39;JobInvolvement&#39;])
Competition2[,&#39;Education&#39;]&lt;-factor(Competition2[,&#39;Education&#39;])
Competition2[,&#39;JobRole&#39;]&lt;-factor(Competition2[,&#39;JobRole&#39;])
Competition2[,&#39;BusinessTravel&#39;]&lt;-factor(Competition2[,&#39;BusinessTravel&#39;])

#Model4 Predictions on Competition set
Competition2$MonthlyIncome &lt;- predict(model4, Competition2)

#Select Columns to output
Competition2.predictions &lt;- Competition2 %&gt;% select(ID,MonthlyIncome)

#Output File with predictions
write.csv(Competition2.predictions,&quot;/Users/rickfontenot/Dropbox/SMU/GitHub/SMU/DS6306/CaseStudy2/Case2PredictionsFontenot Salary.csv&quot;, row.names = TRUE)</code></pre>
<p>Explore JobRole specific trends</p>
<pre class="r"><code>#Create dataframe of numerical independent variables excluding Over18,StandardHours,EmployeeCount

Numerical3 &lt;- DDS %&gt;% select(-DDS_categorical,-JobRoleBin,-Over18,-StandardHours,-EmployeeCount,JobRole)

Numerical3_long &lt;- gather(Numerical3, key=&quot;variable&quot;, value=&quot;value&quot;,-c(ID,JobRole))

stat.test3 &lt;- Numerical3_long %&gt;%
  group_by(variable) %&gt;%
  t_test(value ~ JobRole) %&gt;%
  adjust_pvalue(method = &quot;BH&quot;) %&gt;%
  add_significance()

stat.test3 &lt;- stat.test3 %&gt;% select(p, everything())
stat.test3 &lt;- stat.test3[order(stat.test3$p),] 
stat.test3</code></pre>
<pre><code>## # A tibble: 864 x 11
##           p variable .y.   group1 group2    n1    n2 statistic    df    p.adj
##       &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
##  1 3.88e-73 JobLevel value Resea… Sales…   172   200     -23.1 361.  3.35e-70
##  2 8.03e-65 JobLevel value Sales… Sales…   200    53      25.3 204.  3.47e-62
##  3 1.39e-56 JobLevel value Labor… Sales…   153   200     -19.3 344.  4.00e-54
##  4 2.79e-54 Monthly… value Labor… Sales…   153   200     -19.1 308.  6.03e-52
##  5 1.06e-53 Monthly… value Sales… Sales…   200    53      20.6 225.  1.83e-51
##  6 1.76e-53 Monthly… value Resea… Sales…   172   200     -18.8 317.  2.53e-51
##  7 1.27e-48 Monthly… value Manag… Sales…    51    53      42.5  64.0 1.57e-46
##  8 8.25e-46 Monthly… value Manag… Resea…    51   172      41.6  59.7 8.91e-44
##  9 1.21e-45 Monthly… value Labor… Manag…   153    51     -41.8  59.2 1.16e-43
## 10 1.51e-44 Monthly… value Manag… Manuf…    51    87      22.4 119.  1.30e-42
## # … with 854 more rows, and 1 more variable: p.adj.signif &lt;chr&gt;</code></pre>
<pre class="r"><code>par(mar=c(12,5,1,1))   # extra large bottom margin
plot(Numerical3$JobRole,Numerical3$JobLevel, ylab=&quot;JobLevel&quot;,las=2)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/JobRole-1.png" width="672" /></p>
<pre class="r"><code>plot(Numerical3$JobRole,Numerical3$MonthlyIncome, ylab=&quot;MonthlyIncome&quot;,las=2)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/JobRole-2.png" width="672" /></p>
<pre class="r"><code>plot(Numerical3$JobRole,Numerical3$TotalWorkingYears, ylab=&quot;TotalWorkingYears&quot;,las=2)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/JobRole-3.png" width="672" /></p>
<pre class="r"><code>plot(Numerical3$JobRole,Numerical3$Age, ylab=&quot;Age&quot;,las=2)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/JobRole-4.png" width="672" /></p>
<pre class="r"><code>plot(Numerical3$JobRole,Numerical3$YearsAtCompany, ylab=&quot;YearsAtCompany&quot;,las=2)</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/JobRole-5.png" width="672" /></p>
<pre class="r"><code>MaritalStatus = table(DDS$JobRole, DDS$MaritalStatus)
mosaicplot(MaritalStatus, shade = TRUE, las=2, main = &quot;MaritalStatus&quot;, pop = FALSE)</code></pre>
<pre><code>## Warning: In mosaicplot.default(MaritalStatus, shade = TRUE, las = 2, main = &quot;MaritalStatus&quot;, 
##     pop = FALSE) :
##  extra argument &#39;pop&#39; will be disregarded</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/JobRole-6.png" width="672" /></p>
<pre class="r"><code>MaritalStatus</code></pre>
<pre><code>##                            
##                             Divorced Married Single
##   Healthcare Representative       18      38     20
##   Human Resources                  8      13      6
##   Laboratory Technician           28      71     54
##   Manager                          9      31     11
##   Manufacturing Director          24      44     19
##   Research Director               13      28     10
##   Research Scientist              40      74     58
##   Sales Executive                 45      90     65
##   Sales Representative             6      21     26</code></pre>
<pre class="r"><code>#Significantly Higher Rate of Single people within Sales Rep job role

JobSatisfaction = table(DDS$JobRole, DDS$JobSatisfaction)
mosaicplot(JobSatisfaction, shade = TRUE, las=2, main = &quot;JobSatisfaction&quot;, pop = FALSE)</code></pre>
<pre><code>## Warning: In mosaicplot.default(JobSatisfaction, shade = TRUE, las = 2, main = &quot;JobSatisfaction&quot;, 
##     pop = FALSE) :
##  extra argument &#39;pop&#39; will be disregarded</code></pre>
<p><img src="CaseStudy2_ver4_files/figure-html/JobRole-7.png" width="672" /></p>
<pre class="r"><code>JobSatisfaction</code></pre>
<pre><code>##                            
##                              1  2  3  4
##   Healthcare Representative 16  9 23 28
##   Human Resources            5  8  8  6
##   Laboratory Technician     32 31 43 47
##   Manager                   12 14 12 13
##   Manufacturing Director    12 23 29 23
##   Research Director         13 11 16 11
##   Research Scientist        32 31 48 61
##   Sales Executive           48 25 61 66
##   Sales Representative       9 14 14 16</code></pre>
<p>Session Information</p>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.0.2 (2020-06-22)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] grid      stats     graphics  grDevices utils     datasets  methods  
## [8] base     
## 
## other attached packages:
##  [1] CORElearn_1.54.2   rstatix_0.6.0      olsrr_0.5.3        corrplot_0.84     
##  [5] gplots_3.1.1       DataExplorer_0.8.2 table1_1.2.1       ggthemes_4.2.0    
##  [9] mapproj_1.2.7      maps_3.3.0         class_7.3-17       e1071_1.7-4       
## [13] caret_6.0-86       lattice_0.20-41    ggpubr_0.4.0       plotly_4.9.2.1    
## [17] VIM_6.0.0          colorspace_1.4-1   mice_3.12.0        usmap_0.5.1       
## [21] GGally_2.0.0       visdat_0.5.3       forcats_0.5.0      stringr_1.4.0     
## [25] purrr_0.3.4        readr_1.4.0        tidyr_1.1.2        tibble_3.0.3      
## [29] tidyverse_1.3.0    ggplot2_3.3.2      shinyWidgets_0.5.7 dplyr_1.0.2       
## [33] shiny_1.5.0       
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.1.10     igraph_1.2.6        
##   [4] plyr_1.8.6           lazyeval_0.2.2       sp_1.4-4            
##   [7] splines_4.0.2        digest_0.6.25        foreach_1.5.1       
##  [10] htmltools_0.5.0      fansi_0.4.1          magrittr_1.5        
##  [13] cluster_2.1.0        openxlsx_4.2.3       recipes_0.1.15      
##  [16] modelr_0.1.8         gower_0.2.2          ggrepel_0.8.2       
##  [19] rvest_0.3.6          haven_2.3.1          xfun_0.17           
##  [22] crayon_1.3.4         jsonlite_1.7.1       survival_3.1-12     
##  [25] zoo_1.8-8            iterators_1.0.13     glue_1.4.2          
##  [28] gtable_0.3.0         ipred_0.9-9          car_3.0-10          
##  [31] DEoptimR_1.0-8       abind_1.4-5          scales_1.1.1        
##  [34] DBI_1.1.0            Rcpp_1.0.5           plotrix_3.8-1       
##  [37] viridisLite_0.3.0    xtable_1.8-4         laeken_0.5.1        
##  [40] foreign_0.8-80       Formula_1.2-4        stats4_4.0.2        
##  [43] lava_1.6.8.1         prodlim_2019.11.13   vcd_1.4-8           
##  [46] htmlwidgets_1.5.1    httr_1.4.2           RColorBrewer_1.1-2  
##  [49] ellipsis_0.3.1       pkgconfig_2.0.3      reshape_0.8.8       
##  [52] farver_2.0.3         nnet_7.3-14          dbplyr_2.0.0        
##  [55] utf8_1.1.4           tidyselect_1.1.0     labeling_0.3        
##  [58] rlang_0.4.10         reshape2_1.4.4       later_1.1.0.1       
##  [61] munsell_0.5.0        cellranger_1.1.0     tools_4.0.2         
##  [64] cli_2.0.2            generics_0.1.0       ranger_0.12.1       
##  [67] broom_0.7.3          evaluate_0.14        fastmap_1.0.1       
##  [70] goftest_1.2-2        yaml_2.2.1           ModelMetrics_1.2.2.2
##  [73] knitr_1.30           fs_1.5.0             zip_2.1.1           
##  [76] robustbase_0.93-6    caTools_1.18.1       nlme_3.1-148        
##  [79] mime_0.9             xml2_1.3.2           compiler_4.0.2      
##  [82] rstudioapi_0.11      curl_4.3             ggsignif_0.6.0      
##  [85] reprex_0.3.0         stringi_1.5.3        Matrix_1.2-18       
##  [88] vctrs_0.3.4          networkD3_0.4        pillar_1.4.6        
##  [91] lifecycle_0.2.0      lmtest_0.9-38        bitops_1.0-6        
##  [94] data.table_1.13.6    httpuv_1.5.4         R6_2.4.1            
##  [97] promises_1.1.1       rpart.plot_3.0.9     KernSmooth_2.23-17  
## [100] gridExtra_2.3        rio_0.5.16           codetools_0.2-16    
## [103] gtools_3.8.2         boot_1.3-25          MASS_7.3-51.6       
## [106] assertthat_0.2.1     nortest_1.0-4        withr_2.3.0         
## [109] parallel_4.0.2       mgcv_1.8-31          hms_0.5.3           
## [112] rpart_4.1-15         timeDate_3043.102    rmarkdown_2.6       
## [115] carData_3.0-4        pROC_1.16.2          lubridate_1.7.9.2</code></pre>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
